# ğŸ“ BrowerAI æ¨¡å‹è®­ç»ƒå¿«é€Ÿå¼€å§‹

ä»æ”¶é›†æ•°æ®åˆ°éƒ¨ç½²æ¨¡å‹çš„å®Œæ•´æµç¨‹ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

- Python 3.8+
- Rust 1.70+ï¼ˆå·²æœ‰ï¼‰
- è‡³å°‘ 100+ åé¦ˆæ ·æœ¬

## ğŸš€ 5 æ­¥å¼€å§‹è®­ç»ƒ

### æ­¥éª¤ 1: å®‰è£… Python ä¾èµ–

```bash
cd training

# æ–¹å¼ A: è‡ªåŠ¨è®¾ç½®ï¼ˆæ¨èï¼‰
./setup_env.sh

# æ–¹å¼ B: æ‰‹åŠ¨å®‰è£…
pip install -r requirements.txt
```

### æ­¥éª¤ 2: æ”¶é›†è®­ç»ƒæ•°æ®

å›åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œè®¿é—®çœŸå®ç½‘ç«™æ”¶é›†åé¦ˆæ•°æ®ï¼š

```bash
cd ..

# è®¿é—®å¤šä¸ªç½‘ç«™
cargo run --bin browerai -- --learn \
    https://example.com \
    https://github.com \
    https://rust-lang.org \
    https://developer.mozilla.org \
    https://www.wikipedia.org
```

**ç›®æ ‡**: æ”¶é›† 100+ åé¦ˆæ ·æœ¬ï¼ˆè®¿é—® 10-20 ä¸ªç½‘ç«™ï¼‰

### æ­¥éª¤ 3: è®­ç»ƒæ¨¡å‹

```bash
cd training/scripts

# HTML å¤æ‚åº¦é¢„æµ‹æ¨¡å‹
python train_html_complexity.py \
    --data ../data/feedback_*.json \
    --epochs 100

# CSS ä¼˜åŒ–å»ºè®®æ¨¡å‹ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„ CSS è§£æäº‹ä»¶ï¼‰
python train_css_optimizer.py \
    --data ../data/feedback_*.json \
    --epochs 100
```

**è¾“å‡º**: `training/models/*.onnx` å’Œ `*.pth`

### æ­¥éª¤ 4: éªŒè¯æ¨¡å‹

```bash
# éªŒè¯ ONNX æ ¼å¼
python validate_model.py ../models/html_complexity_v1.onnx

# æ€§èƒ½æµ‹è¯•
python validate_model.py ../models/html_complexity_v1.onnx --benchmark
```

### æ­¥éª¤ 5: éƒ¨ç½²æ¨¡å‹

```bash
cd ../..

# 1. å¤åˆ¶æ¨¡å‹åˆ°éƒ¨ç½²ç›®å½•
cp training/models/html_complexity_v1.onnx models/local/

# 2. æ›´æ–°æ¨¡å‹é…ç½®
cat >> models/model_config.toml << EOF

[[models]]
name = "html_complexity_v1"
model_type = "HtmlParser"
path = "html_complexity_v1.onnx"
version = "1.0.0"
enabled = true
EOF

# 3. é‡æ–°ç¼–è¯‘å¯ç”¨ AI
cargo build --release --features ai

# 4. æµ‹è¯•æ•ˆæœ
cargo run --release -- --ai-report
cargo run --release -- --learn https://example.com
```

## ğŸ¯ å®Œæ•´ç¤ºä¾‹

```bash
# å®Œæ•´æµç¨‹ï¼ˆå¤åˆ¶ç²˜è´´è¿è¡Œï¼‰
cd /workspaces/BrowerAI

# 1. å®‰è£…ä¾èµ–
cd training && ./setup_env.sh && cd ..

# 2. æ”¶é›†æ•°æ®ï¼ˆè®¿é—® 10 ä¸ªç½‘ç«™ï¼‰
cargo run -- --learn \
    https://example.com \
    https://github.com \
    https://rust-lang.org \
    https://developer.mozilla.org \
    https://www.wikipedia.org \
    https://stackoverflow.com \
    https://news.ycombinator.com \
    https://reddit.com \
    https://www.python.org \
    https://nodejs.org

# 3. æ£€æŸ¥æ•°æ®é‡
cd training
python -c "
import json, glob
total = sum(len(json.load(open(f))) for f in glob.glob('data/feedback_*.json'))
print(f'æ€»æ ·æœ¬æ•°: {total}')
print('HTML è§£ææ ·æœ¬:', sum(1 for f in glob.glob('data/feedback_*.json') for e in json.load(open(f)) if e.get('type')=='html_parsing'))
"

# 4. è®­ç»ƒæ¨¡å‹
cd scripts
python train_html_complexity.py --epochs 100

# 5. éªŒè¯æ¨¡å‹
python validate_model.py ../models/html_complexity_v1.onnx --benchmark

# 6. éƒ¨ç½²
cd ../..
cp training/models/html_complexity_v1.onnx models/local/

# 7. æµ‹è¯•
cargo build --features ai && cargo run -- --ai-report
```

## ğŸ“Š æ¨èè®­ç»ƒé…ç½®

### æ•°æ®é‡è¾ƒå°‘ (< 500 æ ·æœ¬)

```bash
python train_html_complexity.py \
    --epochs 50 \
    --batch-size 16 \
    --lr 0.001
```

### æ•°æ®é‡ä¸­ç­‰ (500-5000 æ ·æœ¬)

```bash
python train_html_complexity.py \
    --epochs 100 \
    --batch-size 32 \
    --lr 0.001
```

### æ•°æ®é‡å……è¶³ (> 5000 æ ·æœ¬)

```bash
python train_html_complexity.py \
    --epochs 200 \
    --batch-size 64 \
    --lr 0.0005
```

## ğŸ” æ£€æŸ¥è®­ç»ƒæ•ˆæœ

### å¯¹æ¯” AI å¢å¼ºå‰å

```bash
# æ²¡æœ‰ AI (stub mode)
cargo run -- --learn https://example.com
# è¾“å‡º: complexity=0.500 (å›ºå®šå€¼)

# å¯ç”¨çœŸå®æ¨¡å‹
cargo build --features ai
cargo run -- --learn https://example.com
# è¾“å‡º: complexity=0.732 (åŠ¨æ€é¢„æµ‹)
```

### æŸ¥çœ‹æ€§èƒ½æå‡

```bash
# è¿è¡Œ AI æŠ¥å‘Š
cargo run -- --ai-report

# è¾“å‡ºç¤ºä¾‹:
# ã€æ€§èƒ½ç›‘æ§ã€‘
# Model: html_complexity_v1
# Inference count: 50
# Average time: 0.234 ms  âš¡
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ModuleNotFoundError: No module named 'torch'

**è§£å†³**: å®‰è£…ä¾èµ–
```bash
cd training
pip install -r requirements.txt
```

### Q2: è®­ç»ƒæ•°æ®ä¸è¶³ï¼ˆ< 100 æ ·æœ¬ï¼‰

**è§£å†³**: æ”¶é›†æ›´å¤šç½‘ç«™æ•°æ®
```bash
# åˆ›å»º URL åˆ—è¡¨
cat > websites.txt << EOF
https://example.com
https://github.com
https://rust-lang.org
... (æ›´å¤šç½‘ç«™)
EOF

# æ‰¹é‡è®¿é—®
while read url; do
    cargo run -- --learn "$url"
    sleep 5
done < websites.txt
```

### Q3: CUDA out of memory

**è§£å†³**: ä½¿ç”¨ CPU æˆ–å‡å°æ‰¹æ¬¡
```bash
# å¼ºåˆ¶ä½¿ç”¨ CPU
export CUDA_VISIBLE_DEVICES=""
python train_html_complexity.py --batch-size 16
```

### Q4: è®­ç»ƒæŸå¤±ä¸ä¸‹é™

**æ£€æŸ¥**:
1. æ•°æ®è´¨é‡ï¼ˆæ˜¯å¦æœ‰è¶³å¤Ÿå¤šæ ·æ€§ï¼‰
2. å­¦ä¹ ç‡ï¼ˆå°è¯• 0.0001 æˆ– 0.01ï¼‰
3. æ¨¡å‹å®¹é‡ï¼ˆå¢åŠ /å‡å°‘å±‚æ•°ï¼‰
4. è®­ç»ƒè½®æ•°ï¼ˆå¯èƒ½éœ€è¦æ›´å¤šè½®ï¼‰

### Q5: Rust ç«¯åŠ è½½æ¨¡å‹å¤±è´¥

**æ£€æŸ¥**:
1. æ˜¯å¦ç¼–è¯‘æ—¶å¯ç”¨äº† `--features ai`
2. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆ`models/local/*.onnx`ï¼‰
3. `model_config.toml` é…ç½®æ˜¯å¦æ­£ç¡®
4. ONNX æ–‡ä»¶æ˜¯å¦æŸåï¼ˆç”¨ validate_model.py éªŒè¯ï¼‰

## ğŸ“ˆ è¿›é˜¶æŠ€å·§

### è‡ªå®šä¹‰ç‰¹å¾æå–

ä¿®æ”¹ `train_html_complexity.py` ä¸­çš„ `extract_html_features()`:

```python
def extract_html_features(event: dict) -> Tuple[List[float], float]:
    features = []
    
    # æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾
    html_content = event.get('html_content', '')  # éœ€è¦åœ¨åé¦ˆä¸­æ·»åŠ 
    features.append(len(html_content) / 10000)  # å†…å®¹é•¿åº¦
    features.append(html_content.count('<table>'))  # è¡¨æ ¼æ•°é‡
    features.append(html_content.count('<form>'))  # è¡¨å•æ•°é‡
    # ... æ›´å¤šç‰¹å¾
    
    return features, label
```

### è¶…å‚æ•°æœç´¢

```bash
# æµ‹è¯•ä¸åŒå­¦ä¹ ç‡
for lr in 0.0001 0.001 0.01; do
    python train_html_complexity.py \
        --lr $lr \
        --output ../models/html_lr_${lr}.onnx
done

# å¯¹æ¯”æ•ˆæœ
for model in ../models/html_lr_*.onnx; do
    echo "Testing $model"
    python validate_model.py $model --benchmark
done
```

### æ¨¡å‹èåˆ

è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é›†æˆï¼š

```python
# é›†æˆé¢„æµ‹
predictions = []
for model_path in ['model_v1.onnx', 'model_v2.onnx', 'model_v3.onnx']:
    session = ort.InferenceSession(model_path)
    pred = session.run(None, {input_name: features})[0]
    predictions.append(pred)

# å¹³å‡èåˆ
final_pred = np.mean(predictions, axis=0)
```

## ğŸ“ å­¦ä¹ èµ„æº

- **PyTorch æ•™ç¨‹**: https://pytorch.org/tutorials/
- **ONNX æ–‡æ¡£**: https://onnx.ai/onnx/intro/
- **BrowerAI æ–‡æ¡£**: 
  - [LEARNING_GUIDE.md](../../LEARNING_GUIDE.md) - å‚æ•°è°ƒä¼˜
  - [scripts/README.md](scripts/README.md) - è„šæœ¬è¯¦ç»†æ–‡æ¡£
  - [QUICKSTART.md](QUICKSTART.md) - åŸå§‹å¿«é€Ÿå¼€å§‹

## âœ… æ£€æŸ¥æ¸…å•

è®­ç»ƒå‰:
- [ ] Python ä¾èµ–å·²å®‰è£…
- [ ] æ”¶é›†äº† 100+ åé¦ˆæ ·æœ¬
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨äº `training/data/`

è®­ç»ƒä¸­:
- [ ] è®­ç»ƒæŸå¤±é€æ¸ä¸‹é™
- [ ] éªŒè¯æŸå¤±ä¸ä¸Šå‡ï¼ˆæ— è¿‡æ‹Ÿåˆï¼‰
- [ ] æ²¡æœ‰é”™è¯¯æˆ–è­¦å‘Š

è®­ç»ƒå:
- [ ] ONNX æ¨¡å‹éªŒè¯é€šè¿‡
- [ ] æ¨ç†é€Ÿåº¦ < 1ms
- [ ] æ¨¡å‹å·²å¤åˆ¶åˆ° `models/local/`
- [ ] é…ç½®æ–‡ä»¶å·²æ›´æ–°
- [ ] Rust ç¼–è¯‘å¯ç”¨äº† `--features ai`

éƒ¨ç½²å:
- [ ] AI æŠ¥å‘Šæ˜¾ç¤ºæ¨¡å‹å·²åŠ è½½
- [ ] çœŸå®ç½‘ç«™æµ‹è¯•æ˜¾ç¤ºåŠ¨æ€å¤æ‚åº¦
- [ ] æ€§èƒ½ç›‘æ§æ•°æ®æ­£å¸¸

---

ğŸ‰ ç¥è®­ç»ƒé¡ºåˆ©ï¼æœ‰é—®é¢˜è¯·æŸ¥çœ‹ [scripts/README.md](scripts/README.md) æˆ–æäº¤ Issueã€‚
