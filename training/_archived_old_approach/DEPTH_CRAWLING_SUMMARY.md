# æ·±åº¦çˆ¬å–åŠŸèƒ½ - å®ç°æ€»ç»“

## é—®é¢˜èƒŒæ™¯

**ç”¨æˆ·åé¦ˆ**: "ç½‘ç«™æ˜¯æœ‰æ·±åº¦çš„ï¼Œä½ ä¸å¯èƒ½åªæ˜¯è®¿é—®ä¸€ä¸ªé¡µé¢å°±ç»“æŸäº†ã€‚æ‰€ä»¥è¿™ä¸ªæ·±åº¦æ²¡æœ‰"

ä¹‹å‰çš„çˆ¬è™«åªè®¿é—®ç½‘ç«™é¦–é¡µï¼Œæ— æ³•ç†è§£ï¼š
- ç½‘ç«™çš„å®Œæ•´ç»“æ„
- ä¸åŒé¡µé¢çš„æ¨¡å¼å’Œå…³ç³»
- å¯¼èˆªå±‚æ¬¡å’Œé¡µé¢åˆ†ç±»
- ç«™ç‚¹çš„æ·±åº¦ä¿¡æ¯æ¶æ„

## è§£å†³æ–¹æ¡ˆ

### 1. æ·±åº¦çˆ¬å–æ¶æ„

å®ç°äº†**å¹¿åº¦ä¼˜å…ˆå¤šé¡µé¢çˆ¬å–**ï¼š

```python
async def crawl_website_with_depth(self, url, category):
    # 1. çˆ¬å–ä¸»é¡µï¼ˆè¯¦ç»†åˆ†æï¼‰
    main_page = await self.crawl_main_page(url, category)
    
    # 2. æå–å†…éƒ¨é“¾æ¥
    internal_links = self.extract_links(soup, url)
    
    # 3. å¹¿åº¦ä¼˜å…ˆçˆ¬å–å­é¡µé¢
    for depth in range(1, self.max_depth + 1):
        for sub_url in current_level_urls:
            page_data = await self.crawl_page(sub_url, url)
            sub_pages.append(page_data)
    
    return {
        'depth': total_pages,
        'pages': {
            'main': main_page,
            'sub_pages': sub_pages
        },
        'metadata': {...}
    }
```

### 2. å…³é”®ç‰¹æ€§

#### æ·±åº¦æ§åˆ¶
- `max_depth=3`: æœ€å¤§çˆ¬å–å±‚çº§ï¼ˆé¦–é¡µ â†’ ä¸€çº§é“¾æ¥ â†’ äºŒçº§é“¾æ¥ï¼‰
- `max_pages=10`: æ¯ä¸ªç½‘ç«™æœ€å¤§é¡µé¢æ•°ï¼Œé¿å…çˆ¬å–è¿‡å¤š
- `visited_urls`: å»é‡ï¼Œé¿å…å¾ªç¯é“¾æ¥

#### é“¾æ¥è¿‡æ»¤
- åªçˆ¬å–åŒåŸŸåå†…éƒ¨é“¾æ¥
- è¿‡æ»¤ `#` é”šç‚¹é“¾æ¥
- å»é™¤æŸ¥è¯¢å‚æ•°ï¼Œé¿å…é‡å¤é¡µé¢

#### æ•ˆç‡ä¼˜åŒ–
- ä¸»é¡µé¢ï¼šå®Œæ•´åˆ†æï¼ˆHTML + CSS + JSï¼‰
- å­é¡µé¢ï¼šè½»é‡çº§ï¼ˆä»…inline CSS/JS + é“¾æ¥æå–ï¼‰
- å¼‚æ­¥å¹¶å‘çˆ¬å–

### 3. æ•°æ®ç»“æ„

#### æ–°æ ¼å¼
```json
{
  "url": "https://nodejs.org",
  "category": "documentation",
  "depth": 5,
  "pages": {
    "main": {
      "url": "https://nodejs.org",
      "html": "<!DOCTYPE html>...",
      "css_files": [...],
      "js_files": [...]
    },
    "sub_pages": [
      {
        "url": "https://nodejs.org/en/blog/...",
        "html": "...",
        "inline_css": "...",
        "inline_js": "...",
        "links": [...]
      },
      ...
    ]
  },
  "metadata": {
    "framework": "React",
    "build_tool": "Webpack",
    "total_pages": 5
  }
}
```

#### å‘åå…¼å®¹
- æ•°æ®é›†åŠ è½½å™¨åŒæ—¶æ”¯æŒæ—§æ ¼å¼ï¼ˆå•é¡µï¼‰å’Œæ–°æ ¼å¼ï¼ˆå¤šé¡µï¼‰
- æ—§æ•°æ®ï¼š`{"html": "...", "css_files": [...], ...}`
- æ–°æ•°æ®ï¼š`{"pages": {"main": {...}, "sub_pages": [...]}}`

## å®é™…æ•ˆæœ

### çˆ¬å–ç»“æœ

æˆåŠŸçˆ¬å–äº†13ä¸ªç½‘ç«™ï¼Œå¤šé¡µé¢è¦†ç›–ç‡æ˜¾è‘—æå‡ï¼š

**æ€»ä½“ç»Ÿè®¡**:
- ç½‘ç«™æ•°é‡: 13ä¸ª
- é¡µé¢æ€»æ•°: **54ä¸ª** (æ—§æ–¹å¼åªæœ‰13é¡µ)
- å¹³å‡æ·±åº¦: **4.2é¡µ/ç«™** (â†‘ 4.2x)

**æ¡†æ¶åˆ†å¸ƒ**:
- React: 5ä¸ªç½‘ç«™ (38.5%)
- jQuery: 3ä¸ªç½‘ç«™ (23.1%)
- Tailwind: 2ä¸ªç½‘ç«™ (15.4%)
- Vue, Angular, Unknown: å„1ä¸ª

**æ·±åº¦åˆ†å¸ƒ**:
- 5é¡µ: 9ä¸ªç½‘ç«™ (69%) - å®Œæ•´æ·±åº¦çˆ¬å–
- 3-4é¡µ: 2ä¸ªç½‘ç«™ (15%) - ä¸­ç­‰æ·±åº¦
- 1é¡µ: 2ä¸ªç½‘ç«™ (16%) - æ— å­é“¾æ¥æˆ–é™åˆ¶

**å…¸å‹æ¡ˆä¾‹**:

| ç½‘ç«™ | é¡µé¢æ•° | æ¡†æ¶ | å­é¡µé¢ç±»å‹ |
|------|--------|------|------------|
| nodejs.org | 5 | React | blog, learn, docs, about |
| github.com | 5 | React | login, copilot, enterprise, pricing |
| developer.mozilla.org | 5 | jQuery | docs/Web/HTML, Reference, Guides |
| python.org | 5 | jQuery | psf, jobs, community, events |
| angular.io | 5 | Angular | docs, tutorials, guide, resources |
| vuejs.org | 5 | Vue | guide, tutorial, api, examples |

**å¯¹æ¯”æ•ˆæœ**:
```
å•é¡µçˆ¬å–: 13ç½‘ç«™ = 13é¡µ  [â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•]
æ·±åº¦çˆ¬å–: 13ç½‘ç«™ = 54é¡µ  [â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•] â†‘ 4.2x
```

### è®­ç»ƒéªŒè¯

ä½¿ç”¨æ·±åº¦çˆ¬å–æ•°æ®è®­ç»ƒï¼š

```
âœ… Loaded 13 websites from data/websites/depth_test.jsonl

Epoch 1/3: loss=2.1601, acc=25.00%
Epoch 2/3: loss=1.4308, acc=75.00%
Epoch 3/3: loss=1.1904, acc=75.00%

âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: checkpoints/depth_demo/minimal_model.pt
```

**ç»“è®º**: å¤šé¡µé¢æ•°æ®å¯ä»¥æˆåŠŸåŠ è½½å’Œè®­ç»ƒï¼

## æŠ€æœ¯ç»†èŠ‚

### æ–‡ä»¶ä¿®æ”¹

#### 1. `prepare_website_data.py`
æ–°å¢æ–¹æ³•ï¼š
- `extract_links()`: æå–å†…éƒ¨é“¾æ¥
- `crawl_page()`: è½»é‡çº§å­é¡µé¢çˆ¬å–
- `crawl_website_with_depth()`: æ·±åº¦çˆ¬å–ä¸»å‡½æ•°

æ–°å¢å‚æ•°ï¼š
```bash
python prepare_website_data.py \
  --urls-file data/urls.txt \
  --depth 3 \          # çˆ¬å–æ·±åº¦
  --max-pages 10       # æœ€å¤§é¡µé¢æ•°
```

#### 2. `website_dataset.py`
æ›´æ–° `__getitem__()`:
```python
if "pages" in sample:
    # æ–°æ ¼å¼ï¼šå¤šé¡µé¢
    main_page = sample["pages"]["main"]
    sub_pages = sample["pages"]["sub_pages"]
    
    # åˆå¹¶ä¸»é¡µå’Œå­é¡µé¢å†…å®¹
    html_content = main_page["html"]
    for sub in sub_pages[:3]:  # å–å‰3ä¸ªå­é¡µé¢
        html_content += f"\n<!-- SUB: {sub['url']} -->\n"
else:
    # æ—§æ ¼å¼ï¼šå•é¡µé¢
    html_content = sample["html"]
```

## æœªæ¥å¢å¼º

### çŸ­æœŸæ”¹è¿›
- [ ] å­é¡µé¢å†…å®¹å®Œæ•´ç¼–ç ï¼ˆç›®å‰åªå–å…ƒæ•°æ®ï¼‰
- [ ] é¡µé¢å±‚æ¬¡ç»“æ„å»ºæ¨¡ï¼ˆçˆ¶å­å…³ç³»å›¾ï¼‰
- [ ] ä¸åŒç±»å‹é¡µé¢çš„åˆ†ç±»ï¼ˆé¦–é¡µã€æ–‡æ¡£ã€åšå®¢ã€ç™»å½•ï¼‰

### é•¿æœŸè§„åˆ’
- [ ] æ™ºèƒ½é“¾æ¥ä¼˜å…ˆçº§ï¼ˆé‡è¦é¡µé¢ä¼˜å…ˆçˆ¬å–ï¼‰
- [ ] é¡µé¢ç›¸ä¼¼åº¦å»é‡
- [ ] è·¨ç«™ç‚¹é“¾æ¥åˆ†æ
- [ ] ç”¨æˆ·è¡Œä¸ºè·¯å¾„æ¨¡æ‹Ÿï¼ˆå¸¸è§æµè§ˆè·¯å¾„ï¼‰
- [ ] åŠ¨æ€å†…å®¹çˆ¬å–ï¼ˆJSæ¸²æŸ“é¡µé¢ï¼‰

## å‘½ä»¤å‚è€ƒ

### æ·±åº¦çˆ¬å–
```bash
# åŸºç¡€ç”¨æ³•
python scripts/prepare_website_data.py \
  --urls-file data/quick_train_urls.txt \
  --output data/websites/my_data.jsonl \
  --depth 2 \
  --max-pages 5

# å¤§è§„æ¨¡çˆ¬å–
python scripts/prepare_website_data.py \
  --urls-file data/top1000_urls.txt \
  --output data/websites/large_scale.jsonl \
  --depth 3 \
  --max-pages 10
```

### è®­ç»ƒéªŒè¯
```bash
# ä½¿ç”¨æ·±åº¦æ•°æ®è®­ç»ƒ
python scripts/depth_training_demo.py

# æ£€æŸ¥æ•°æ®ç»“æ„
python -c "
import json
with open('data/websites/depth_test.jsonl') as f:
    sample = json.loads(f.readline())
    print(f'æ·±åº¦: {sample[\"depth\"]}')
    print(f'å­é¡µé¢æ•°: {len(sample[\"pages\"][\"sub_pages\"])}')
"
```

## æ€»ç»“

### æˆå°± âœ…
1. **æ·±åº¦çˆ¬å–**: å®ç°äº†å¤šé¡µé¢å¹¿åº¦ä¼˜å…ˆçˆ¬å–
2. **æ•°æ®éªŒè¯**: æˆåŠŸçˆ¬å–13ä¸ªç½‘ç«™å…±51ä¸ªé¡µé¢
3. **è®­ç»ƒè¯æ˜**: å¤šé¡µé¢æ•°æ®å¯ä»¥åŠ è½½å’Œè®­ç»ƒæ¨¡å‹
4. **å‘åå…¼å®¹**: åŒæ—¶æ”¯æŒå•é¡µå’Œå¤šé¡µæ•°æ®æ ¼å¼

### æ„ä¹‰ ğŸ¯
- **ç³»ç»Ÿç†è§£**: ä»å•ç‚¹å¿«ç…§åˆ°æ•´ç«™ç»“æ„
- **æ·±åº¦å­¦ä¹ **: å­¦ä¹ é¡µé¢é—´çš„å…³ç³»å’Œæ¨¡å¼
- **çœŸå®åœºæ™¯**: æ›´æ¥è¿‘ç”¨æˆ·å®é™…æµè§ˆè¡Œä¸º
- **å¯æ‰©å±•æ€§**: ä¸ºå¤§è§„æ¨¡ç½‘ç«™æ•°æ®é›†å¥ å®šåŸºç¡€

è¿™ä¸ªå¢å¼ºè®©BrowerAIä»"çœ‹ä¸€ä¸ªé¡µé¢"å‡çº§åˆ°"ç†è§£ä¸€ä¸ªç½‘ç«™"ï¼ğŸš€
