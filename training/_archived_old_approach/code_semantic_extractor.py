#!/usr/bin/env python3
"""
ä»£ç è¯­ä¹‰ç‰¹å¾æå–å™¨ - è½»é‡çº§å®ç°
ä¸ä¾èµ–å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨ASTå’Œå¯å‘å¼æ–¹æ³•æå–è¯­ä¹‰ç‰¹å¾
"""

import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Any
from collections import Counter
import hashlib


class CodeSemanticExtractor:
    """è½»é‡çº§ä»£ç è¯­ä¹‰ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        # è¯­ä¹‰å…³é”®è¯è¯å…¸
        self.html_semantic_tags = {
            'header', 'nav', 'main', 'article', 'section', 'aside', 
            'footer', 'figure', 'figcaption', 'details', 'summary'
        }
        
        self.js_semantic_patterns = {
            'event_listener': r'addEventListener\(',
            'promise': r'\.then\(|\.catch\(|new Promise\(',
            'async_await': r'async\s+function|await\s+',
            'class_definition': r'class\s+\w+',
            'arrow_function': r'=>',
            'destructuring': r'const\s*\{|\[\s*\w+\s*\]',
            'spread_operator': r'\.\.\.',
            'template_literal': r'`[^`]*`',
            'module_import': r'import\s+.*from',
            'module_export': r'export\s+(default|const|class|function)',
        }
        
        self.css_semantic_features = {
            'grid_layout': r'display:\s*grid|grid-template',
            'flex_layout': r'display:\s*flex|flex-direction',
            'responsive': r'@media',
            'animation': r'@keyframes|animation:',
            'transition': r'transition:',
            'variable': r'var\(--',
            'pseudo_class': r':[a-z-]+\(',
            'pseudo_element': r'::[a-z-]+',
        }
    
    def extract_html_semantic(self, html: str) -> Dict[str, Any]:
        """æå–HTMLè¯­ä¹‰ç‰¹å¾"""
        features = {}
        
        # è¯­ä¹‰æ ‡ç­¾ä½¿ç”¨ç‡
        semantic_count = sum(html.lower().count(f'<{tag}') for tag in self.html_semantic_tags)
        all_tags = len(re.findall(r'<(\w+)', html))
        features['semantic_tag_ratio'] = semantic_count / max(all_tags, 1)
        
        # æ–‡æ¡£ç»“æ„
        features['has_header'] = '<header' in html.lower()
        features['has_nav'] = '<nav' in html.lower()
        features['has_main'] = '<main' in html.lower()
        features['has_footer'] = '<footer' in html.lower()
        features['has_article'] = '<article' in html.lower()
        
        # ARIA å¯è®¿é—®æ€§
        aria_count = len(re.findall(r'aria-[\w-]+', html))
        features['aria_usage'] = aria_count / max(all_tags, 1)
        
        # å¾®æ•°æ®/Schema.org
        features['has_microdata'] = 'itemscope' in html or 'itemtype' in html
        features['has_json_ld'] = 'application/ld+json' in html
        
        # è¡¨å•ç»“æ„
        form_elements = ['input', 'select', 'textarea', 'button']
        features['form_complexity'] = sum(html.lower().count(f'<{el}') for el in form_elements)
        
        # å¤šåª’ä½“å†…å®¹
        features['image_count'] = html.lower().count('<img')
        features['video_count'] = html.lower().count('<video')
        features['audio_count'] = html.lower().count('<audio')
        
        # äº¤äº’å…ƒç´ 
        features['interactive_count'] = (
            html.count('onclick') + 
            html.count('onsubmit') +
            html.count('data-action')
        )
        
        return features
    
    def extract_js_semantic(self, js_code: str) -> Dict[str, Any]:
        """æå–JavaScriptè¯­ä¹‰ç‰¹å¾"""
        features = {}
        
        # ä»£ç æ¨¡å¼æ£€æµ‹
        for pattern_name, pattern in self.js_semantic_patterns.items():
            matches = len(re.findall(pattern, js_code))
            features[f'pattern_{pattern_name}'] = matches
        
        # ç¼–ç¨‹èŒƒå¼
        features['oop_score'] = (
            js_code.count('class ') +
            js_code.count('this.') +
            js_code.count('prototype.')
        )
        
        features['functional_score'] = (
            js_code.count('.map(') +
            js_code.count('.filter(') +
            js_code.count('.reduce(') +
            js_code.count('=>')
        )
        
        # æ¡†æ¶ç‰¹å¾
        features['react_signals'] = (
            js_code.count('React.') +
            js_code.count('useState') +
            js_code.count('useEffect') +
            js_code.count('jsx')
        )
        
        features['vue_signals'] = (
            js_code.count('Vue.') +
            js_code.count('v-if') +
            js_code.count('v-for') +
            js_code.count('$emit')
        )
        
        features['jquery_signals'] = (
            js_code.count('$(') +
            js_code.count('jQuery(') +
            js_code.count('.ajax')
        )
        
        # å¼‚æ­¥ç¼–ç¨‹å¤æ‚åº¦
        features['async_complexity'] = (
            features['pattern_promise'] +
            features['pattern_async_await'] * 2  # async/awaitæƒé‡æ›´é«˜
        )
        
        # æ¨¡å—åŒ–ç¨‹åº¦
        features['modularity'] = (
            features['pattern_module_import'] +
            features['pattern_module_export']
        )
        
        # ä»£ç è´¨é‡æŒ‡æ ‡
        features['variable_count'] = len(re.findall(r'\b(const|let|var)\b', js_code))
        features['function_count'] = len(re.findall(r'\bfunction\b|\bconst\s+\w+\s*=\s*\(', js_code))
        features['code_density'] = len(js_code.split()) / max(js_code.count('\n'), 1)
        
        return features
    
    def extract_css_semantic(self, css_code: str) -> Dict[str, Any]:
        """æå–CSSè¯­ä¹‰ç‰¹å¾"""
        features = {}
        
        # å¸ƒå±€æ¨¡å¼
        for pattern_name, pattern in self.css_semantic_features.items():
            matches = len(re.findall(pattern, css_code, re.IGNORECASE))
            features[f'feature_{pattern_name}'] = matches
        
        # é€‰æ‹©å™¨å¤æ‚åº¦
        selectors = re.findall(r'([^{]+)\s*\{', css_code)
        if selectors:
            avg_selector_parts = sum(s.count(' ') + s.count('>') + s.count('+') for s in selectors) / len(selectors)
            features['selector_complexity'] = avg_selector_parts
        else:
            features['selector_complexity'] = 0
        
        # é¢œè‰²ä½¿ç”¨
        hex_colors = len(re.findall(r'#[0-9a-fA-F]{3,6}', css_code))
        rgb_colors = len(re.findall(r'rgba?\(', css_code))
        features['color_diversity'] = hex_colors + rgb_colors
        
        # CSSå˜é‡ä½¿ç”¨ï¼ˆç°ä»£åŒ–æŒ‡æ ‡ï¼‰
        features['uses_variables'] = '--' in css_code
        features['variable_count'] = css_code.count('var(--')
        
        # å“åº”å¼è®¾è®¡
        media_queries = len(re.findall(r'@media', css_code))
        features['responsive_design'] = media_queries
        
        # åŠ¨ç”»å’Œè¿‡æ¸¡
        features['animation_usage'] = (
            features['feature_animation'] +
            features['feature_transition']
        )
        
        # æµè§ˆå™¨å‰ç¼€ï¼ˆå…¼å®¹æ€§æŒ‡æ ‡ï¼‰
        prefixes = ['-webkit-', '-moz-', '-ms-', '-o-']
        features['browser_prefix_count'] = sum(css_code.count(prefix) for prefix in prefixes)
        
        # ä¼ªå…ƒç´ /ä¼ªç±»ä½¿ç”¨ï¼ˆé«˜çº§ç‰¹æ€§ï¼‰
        features['advanced_selectors'] = (
            features['feature_pseudo_class'] +
            features['feature_pseudo_element']
        )
        
        return features
    
    def compute_semantic_hash(self, features: Dict[str, Any]) -> str:
        """è®¡ç®—ç‰¹å¾å‘é‡çš„è¯­ä¹‰å“ˆå¸Œ"""
        # å°†ç‰¹å¾è½¬æ¢ä¸ºç¨³å®šçš„å­—ç¬¦ä¸²è¡¨ç¤º
        feature_str = json.dumps(features, sort_keys=True)
        return hashlib.md5(feature_str.encode()).hexdigest()[:16]
    
    def extract_all(self, html: str, css: str, js: str) -> Dict[str, Any]:
        """æå–å®Œæ•´é¡µé¢çš„è¯­ä¹‰ç‰¹å¾"""
        html_features = self.extract_html_semantic(html)
        css_features = self.extract_css_semantic(css)
        js_features = self.extract_js_semantic(js)
        
        # ç»„åˆç‰¹å¾
        combined = {
            'html': html_features,
            'css': css_features,
            'js': js_features,
        }
        
        # è®¡ç®—æ•´ä½“è¯­ä¹‰å‘é‡
        all_numeric = []
        for category in combined.values():
            for value in category.values():
                if isinstance(value, (int, float)):
                    all_numeric.append(value)
                elif isinstance(value, bool):
                    all_numeric.append(1.0 if value else 0.0)
        
        combined['semantic_vector'] = all_numeric
        combined['semantic_hash'] = self.compute_semantic_hash(combined)
        combined['vector_dim'] = len(all_numeric)
        
        return combined


def main():
    """æµ‹è¯•è¯­ä¹‰æå–å™¨"""
    import sys
    
    extractor = CodeSemanticExtractor()
    
    # è¯»å–ç°æœ‰åé¦ˆæ•°æ®æµ‹è¯•
    data_dir = Path(__file__).parent.parent / 'data'
    feedback_files = list(data_dir.glob('feedback_*.json'))
    
    if not feedback_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åé¦ˆæ•°æ®æ–‡ä»¶")
        return 1
    
    print(f"ğŸ“Š å¤„ç† {len(feedback_files)} ä¸ªåé¦ˆæ–‡ä»¶...")
    
    results = []
    processed = 0
    
    for feedback_file in feedback_files[:10]:  # å…ˆæµ‹è¯•10ä¸ª
        try:
            with open(feedback_file) as f:
                data = json.load(f)
            
            # æ•°æ®å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸
            events = data if isinstance(data, list) else data.get('events', [])
            
            # æå–å†…å®¹
            html_content = ""
            css_content = ""
            js_content = ""
            url = "unknown"
            
            for event in events:
                event_type = event.get('type', event.get('event_type', ''))
                
                if event_type == 'html_parsing':
                    # å°è¯•ä»eventä¸­æå–å†…å®¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    pass
                elif event_type == 'css_parsing':
                    pass
                elif event_type == 'js_parsing':
                    pass
            
            # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œä½¿ç”¨æå–çš„ç‰¹å¾æ–‡ä»¶
            if not (html_content or css_content or js_content):
                # è·³è¿‡ç©ºæ–‡ä»¶
                continue
            
            features = extractor.extract_all(html_content, css_content, js_content)
            
            results.append({
                'file': feedback_file.name,
                'url': url,
                'features': features,
            })
            
            processed += 1
        
        except Exception as e:
            print(f"âš ï¸ å¤„ç† {feedback_file.name} å¤±è´¥: {e}")
    
    print(f"\nâœ… æˆåŠŸæå– {processed} ä¸ªæ ·æœ¬çš„è¯­ä¹‰ç‰¹å¾")
    
    if results:
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾
        sample = results[0]
        print(f"\nğŸ“‹ æ ·æœ¬ç¤ºä¾‹: {sample['url']}")
        print(f"   è¯­ä¹‰å‘é‡ç»´åº¦: {sample['features']['vector_dim']}")
        print(f"   è¯­ä¹‰å“ˆå¸Œ: {sample['features']['semantic_hash']}")
        print(f"\n   HTMLç‰¹å¾:")
        for k, v in list(sample['features']['html'].items())[:5]:
            print(f"      {k}: {v}")
        print(f"\n   JSç‰¹å¾:")
        for k, v in list(sample['features']['js'].items())[:5]:
            print(f"      {k}: {v}")
        print(f"\n   CSSç‰¹å¾:")
        for k, v in list(sample['features']['css'].items())[:5]:
            print(f"      {k}: {v}")
        
        # ä¿å­˜ç»“æœ
        output_file = Path(__file__).parent.parent / 'features' / 'semantic_features.json'
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯­ä¹‰ç‰¹å¾å·²ä¿å­˜: {output_file}")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
