#!/usr/bin/env python3
"""
ONNX æ¨¡å‹éªŒè¯å’Œæµ‹è¯•è„šæœ¬

ç”¨æ³•:
    python validate_model.py ../models/html_complexity_v1.onnx
"""

import sys
import time
import argparse
import numpy as np

try:
    import onnx
    import onnxruntime as ort
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–ï¼è¯·å®‰è£…:")
    print("   pip install onnx onnxruntime")
    sys.exit(1)


def validate_onnx_model(model_path: str):
    """éªŒè¯ ONNX æ¨¡å‹æ ¼å¼"""
    print(f"ğŸ“‹ éªŒè¯æ¨¡å‹: {model_path}")
    
    try:
        model = onnx.load(model_path)
        onnx.checker.check_model(model)
        print("âœ… ONNX æ ¼å¼éªŒè¯é€šè¿‡")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"   Opset ç‰ˆæœ¬: {model.opset_import[0].version}")
        print(f"   IR ç‰ˆæœ¬: {model.ir_version}")
        
        # è¾“å…¥ä¿¡æ¯
        print(f"\nğŸ“¥ æ¨¡å‹è¾“å…¥:")
        for input_tensor in model.graph.input:
            dims = [d.dim_value if d.dim_value > 0 else 'dynamic' 
                   for d in input_tensor.type.tensor_type.shape.dim]
            print(f"   - {input_tensor.name}: {dims}")
        
        # è¾“å‡ºä¿¡æ¯
        print(f"\nğŸ“¤ æ¨¡å‹è¾“å‡º:")
        for output_tensor in model.graph.output:
            dims = [d.dim_value if d.dim_value > 0 else 'dynamic' 
                   for d in output_tensor.type.tensor_type.shape.dim]
            print(f"   - {output_tensor.name}: {dims}")
        
        return True
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False


def benchmark_model(model_path: str, num_runs: int = 1000):
    """æ€§èƒ½æµ‹è¯•"""
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯•ï¼ˆ{num_runs} æ¬¡æ¨ç†ï¼‰...")
    
    try:
        # åˆ›å»ºæ¨ç†ä¼šè¯
        session = ort.InferenceSession(
            model_path,
            providers=['CPUExecutionProvider']
        )
        
        # è·å–è¾“å…¥ä¿¡æ¯
        input_name = session.get_inputs()[0].name
        input_shape = session.get_inputs()[0].shape
        
        # å¤„ç†åŠ¨æ€ç»´åº¦
        batch_size = 1
        feature_dim = input_shape[1] if len(input_shape) > 1 else input_shape[0]
        
        # ç”Ÿæˆéšæœºè¾“å…¥
        input_data = np.random.randn(batch_size, feature_dim).astype(np.float32)
        
        # é¢„çƒ­
        for _ in range(10):
            session.run(None, {input_name: input_data})
        
        # åŸºå‡†æµ‹è¯•
        start = time.time()
        for _ in range(num_runs):
            outputs = session.run(None, {input_name: input_data})
        end = time.time()
        
        avg_time_ms = (end - start) / num_runs * 1000
        
        print(f"âœ… å¹³å‡æ¨ç†æ—¶é—´: {avg_time_ms:.3f} ms")
        print(f"âœ… ååé‡: {1000/avg_time_ms:.1f} æ¬¡/ç§’")
        
        # æµ‹è¯•æ‰¹é‡æ¨ç†
        batch_sizes = [1, 10, 100]
        print(f"\nğŸ“Š æ‰¹é‡æ¨ç†æµ‹è¯•:")
        for bs in batch_sizes:
            batch_input = np.random.randn(bs, feature_dim).astype(np.float32)
            start = time.time()
            for _ in range(100):
                session.run(None, {input_name: batch_input})
            elapsed = time.time() - start
            per_sample = elapsed / 100 / bs * 1000
            print(f"   Batch {bs}: {per_sample:.3f} ms/æ ·æœ¬")
        
        return True
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_inference(model_path: str):
    """æµ‹è¯•æ¨ç†åŠŸèƒ½"""
    print(f"\nğŸ§ª æ¨ç†åŠŸèƒ½æµ‹è¯•...")
    
    try:
        session = ort.InferenceSession(model_path)
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        
        # æµ‹è¯•ä¸åŒè¾“å…¥
        test_cases = [
            ("å…¨é›¶è¾“å…¥", np.zeros((1, session.get_inputs()[0].shape[1]), dtype=np.float32)),
            ("å…¨ä¸€è¾“å…¥", np.ones((1, session.get_inputs()[0].shape[1]), dtype=np.float32)),
            ("éšæœºè¾“å…¥", np.random.randn(1, session.get_inputs()[0].shape[1]).astype(np.float32)),
        ]
        
        for name, input_data in test_cases:
            outputs = session.run([output_name], {input_name: input_data})
            result = outputs[0][0]
            
            if len(result.shape) == 0:  # æ ‡é‡
                print(f"   {name}: {result:.4f}")
            else:  # å‘é‡
                print(f"   {name}: {result}")
        
        print("âœ… æ¨ç†åŠŸèƒ½æ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='éªŒè¯ ONNX æ¨¡å‹')
    parser.add_argument('model', type=str, help='ONNX æ¨¡å‹è·¯å¾„')
    parser.add_argument('--benchmark', action='store_true', help='è¿è¡Œæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--runs', type=int, default=1000, help='åŸºå‡†æµ‹è¯•æ¬¡æ•°')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("BrowerAI ONNX æ¨¡å‹éªŒè¯å·¥å…·")
    print("=" * 60)
    
    # éªŒè¯æ¨¡å‹
    if not validate_onnx_model(args.model):
        sys.exit(1)
    
    # æµ‹è¯•æ¨ç†
    if not test_inference(args.model):
        sys.exit(1)
    
    # æ€§èƒ½æµ‹è¯•
    if args.benchmark:
        if not benchmark_model(args.model, args.runs):
            sys.exit(1)
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)


if __name__ == '__main__':
    main()
